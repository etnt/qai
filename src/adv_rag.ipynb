{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLPTw9xhQqUt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k20225YI4ifh"
      },
      "source": [
        "# Advanced RAG 01: Small to Big\n",
        "\n",
        "### Child-Parent RecursiveRetriever and Sentence Window Retrieval with LlamaIndex\n",
        "\n",
        "Sources:\n",
        "- https://docs.llamaindex.ai/en/stable/examples/retrievers/recursive_retriever_nodes.html\n",
        "- https://docs.llamaindex.ai/en/latest/examples/node_postprocessor/MetadataReplacementDemo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0L1ZfgxqPNf",
        "outputId": "3b8f6fa8-0160-41ca-cf70-330bdc87d8c4"
      },
      "outputs": [],
      "source": [
        "# ! pip install -U llama_hub llama_index braintrust autoevals pypdf pillow transformers torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbirJ-0R3bjz"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"TYPE YOUR API KEY HERE\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxnMKsUN3fr-",
        "outputId": "39e2b3fc-35d2-4343-8004-43f7be575b64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-19 14:16:58--  https://arxiv.org/pdf/2307.09288.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.131.42, 151.101.195.42, 151.101.3.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.131.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13661300 (13M) [application/pdf]\n",
            "Saving to: ‘llama2.pdf’\n",
            "\n",
            "llama2.pdf          100%[===================>]  13,03M  6,17MB/s    in 2,1s    \n",
            "\n",
            "2024-04-19 14:17:00 (6,17 MB/s) - ‘llama2.pdf’ saved [13661300/13661300]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"llama2.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMofKy8tSf99"
      },
      "source": [
        "# Basic RAG Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UQ44weGBqqYG"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'llama_index.readers.base'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFReader\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display_source_node\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretrievers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveRetriever\n",
            "File \u001b[0;32m~/git/qai/pyvenv/lib/python3.12/site-packages/llama_hub/file/pdf/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Init file.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     PDFReader,\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDFReader\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/git/qai/pyvenv/lib/python3.12/site-packages/llama_hub/file/pdf/base.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IO, Dict, List, Optional, Union\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseReader\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPDFReader\u001b[39;00m(BaseReader):\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.readers.base'"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from llama_hub.file.pdf.base import PDFReader\n",
        "from llama_index.response.notebook_utils import display_source_node\n",
        "from llama_index.retrievers import RecursiveRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index import VectorStoreIndex, ServiceContext\n",
        "from llama_index.llms import OpenAI\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScMsd6fSSqL2"
      },
      "source": [
        "### Step 1: Loading Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OkXdENA1qsO4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'PDFReader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m loader \u001b[38;5;241m=\u001b[39m \u001b[43mPDFReader\u001b[49m()\n\u001b[1;32m      2\u001b[0m docs0 \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload_data(file\u001b[38;5;241m=\u001b[39mPath(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama2.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PDFReader' is not defined"
          ]
        }
      ],
      "source": [
        "loader = PDFReader()\n",
        "docs0 = loader.load_data(file=Path(\"llama2.pdf\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq4pBk92TNEk",
        "outputId": "4de7e667-31a8-48f4-c90a-4bb83c06e283"
      },
      "outputs": [],
      "source": [
        "docs0[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "N0wxq1l6qtTl"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'docs0' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m----> 3\u001b[0m doc_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([d\u001b[38;5;241m.\u001b[39mget_content() \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdocs0\u001b[49m])\n\u001b[1;32m      4\u001b[0m docs \u001b[38;5;241m=\u001b[39m [Document(text\u001b[38;5;241m=\u001b[39mdoc_text)]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'docs0' is not defined"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Document\n",
        "\n",
        "doc_text = \"\\n\\n\".join([d.get_content() for d in docs0])\n",
        "docs = [Document(text=doc_text)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NkYqcZDSvZM"
      },
      "source": [
        "### Step 2: Parsing Documents into Text Chunks (Nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwyfDZg8quVJ"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "from llama_index.schema import IndexNode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jtEc7QiqwOL"
      },
      "outputs": [],
      "source": [
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOCx6xhPYrjI",
        "outputId": "e1ba3b9b-8e07-4f95-da6c-af5e26bbf7f8"
      },
      "outputs": [],
      "source": [
        "node_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PwFBSYdqxZB"
      },
      "outputs": [],
      "source": [
        "base_nodes = node_parser.get_nodes_from_documents(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtCNy-EYSQnX",
        "outputId": "f8f943a9-30dd-4928-f48f-2488f9456f2b"
      },
      "outputs": [],
      "source": [
        "base_nodes[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjn9e6hOSMYx"
      },
      "outputs": [],
      "source": [
        "# set node ids to be a constant\n",
        "for idx, node in enumerate(base_nodes):\n",
        "    node.id_ = f\"node-{idx}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mjamtA7YvvO",
        "outputId": "23151841-d452-4e9c-aa60-6cf4bff2ee95"
      },
      "outputs": [],
      "source": [
        "base_nodes[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2msA59qS10V"
      },
      "source": [
        "### Step 3: Select Embedding Model and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awCBMmzuqypC"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings import resolve_embed_model\n",
        "\n",
        "\n",
        "\n",
        "embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
        "service_context = ServiceContext.from_defaults(\n",
        "    llm=llm, embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BpGcyXIS7Hb"
      },
      "source": [
        "### Step 4: Create Index, retriever, and query engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-V8NQgHq0Ae"
      },
      "outputs": [],
      "source": [
        "base_index = VectorStoreIndex(base_nodes, service_context=service_context)\n",
        "base_retriever = base_index.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2C_4Fe4Pq2fx"
      },
      "outputs": [],
      "source": [
        "retrievals = base_retriever.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "C8OMXJpaq5oR",
        "outputId": "7646712d-0d1d-4bc1-d2b3-272a36057449"
      },
      "outputs": [],
      "source": [
        "for n in retrievals:\n",
        "    display_source_node(n, source_length=1500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ey8fw_Xq9Yb"
      },
      "outputs": [],
      "source": [
        "query_engine_base = RetrieverQueryEngine.from_args(\n",
        "    base_retriever, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4C2uUn-Wq_C4",
        "outputId": "f9b29366-32c4-4520-f8cf-2ae05f1c5620"
      },
      "outputs": [],
      "source": [
        "response = query_engine_base.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XGmqQ5z8k4t"
      },
      "source": [
        "# Chunk References: Smaller Child Chunks Referring to Bigger Parent Chunk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaAiq97Nq_4v"
      },
      "outputs": [],
      "source": [
        "sub_chunk_sizes = [128, 256, 512]\n",
        "sub_node_parsers = [\n",
        "    SimpleNodeParser.from_defaults(chunk_size=c) for c in sub_chunk_sizes\n",
        "]\n",
        "\n",
        "all_nodes = []\n",
        "for base_node in base_nodes:\n",
        "    for n in sub_node_parsers:\n",
        "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
        "        sub_inodes = [\n",
        "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
        "        ]\n",
        "        all_nodes.extend(sub_inodes)\n",
        "\n",
        "    # also add original node to node\n",
        "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
        "    all_nodes.append(original_node)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V_-7-mXrA6R"
      },
      "outputs": [],
      "source": [
        "all_nodes_dict = {n.node_id: n for n in all_nodes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ne0rYmDTl5A",
        "outputId": "f7b7fb2c-5a43-4ab8-a818-e07ec8116f8f"
      },
      "outputs": [],
      "source": [
        "len(all_nodes_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHBxFUCQjiop",
        "outputId": "7a31d40d-fc57-4a0e-fe6c-1eb77e266b72"
      },
      "outputs": [],
      "source": [
        "all_nodes_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcBPNjKOrCGE"
      },
      "outputs": [],
      "source": [
        "vector_index_chunk = VectorStoreIndex(\n",
        "    all_nodes, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyDn8WQVrDZ-"
      },
      "outputs": [],
      "source": [
        "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3t3YyCov8Z0V"
      },
      "outputs": [],
      "source": [
        "retriever_chunk = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "l8BMwy7N8a7Y",
        "outputId": "b1ada559-2bac-4168-f8dd-064bd221ace1"
      },
      "outputs": [],
      "source": [
        "nodes = retriever_chunk.retrieve(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "for node in nodes:\n",
        "    display_source_node(node, source_length=2000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys5kVd2N8cIm"
      },
      "outputs": [],
      "source": [
        "query_engine_chunk = RetrieverQueryEngine.from_args(\n",
        "    retriever_chunk, service_context=service_context\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkTD2Vhf8fCk",
        "outputId": "bc8bff6b-7631-459e-b292-08a8a3f932f0"
      },
      "outputs": [],
      "source": [
        "response = query_engine_chunk.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFNJJl7u3vI0"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2siSjRog3wLu"
      },
      "outputs": [],
      "source": [
        "from llama_index.evaluation import (\n",
        "    generate_question_context_pairs,\n",
        "    EmbeddingQAFinetuneDataset,\n",
        ")\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyx-ITdG8qQA",
        "outputId": "acdc254e-5be4-46a9-b3ab-37ceb30678a9"
      },
      "outputs": [],
      "source": [
        "eval_dataset = generate_question_context_pairs(base_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fVETf-h8shR"
      },
      "outputs": [],
      "source": [
        "eval_dataset.save_json(\"llama2_eval_dataset.json\")\n",
        "# eval_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/llama2_eval_dataset.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ev-0XNWc85jY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from llama_index.evaluation import RetrieverEvaluator, get_retrieval_results_df\n",
        "\n",
        "# set vector retriever similarity top k to higher\n",
        "top_k = 10\n",
        "\n",
        "\n",
        "def display_results(names, results_arr):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    hit_rates = []\n",
        "    mrrs = []\n",
        "    for name, eval_results in zip(names, results_arr):\n",
        "        metric_dicts = []\n",
        "        for eval_result in eval_results:\n",
        "            metric_dict = eval_result.metric_vals_dict\n",
        "            metric_dicts.append(metric_dict)\n",
        "        results_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "        hit_rate = results_df[\"hit_rate\"].mean()\n",
        "        mrr = results_df[\"mrr\"].mean()\n",
        "        hit_rates.append(hit_rate)\n",
        "        mrrs.append(mrr)\n",
        "\n",
        "    final_df = pd.DataFrame(\n",
        "        {\"retrievers\": names, \"hit_rate\": hit_rates, \"mrr\": mrrs}\n",
        "    )\n",
        "    display(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGQBgWOb88PZ",
        "outputId": "02a695c4-25c7-4233-8370-a129c8a90d95"
      },
      "outputs": [],
      "source": [
        "# base\n",
        "base_retriever = base_index.as_retriever(similarity_top_k=top_k)\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
        ")\n",
        "results_base = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJNrlsW39y11",
        "outputId": "0ad2aea2-f559-4207-9751-7141c1084f0b"
      },
      "outputs": [],
      "source": [
        "# chunk\n",
        "vector_retriever_chunk = vector_index_chunk.as_retriever(\n",
        "    similarity_top_k=top_k\n",
        ")\n",
        "retriever_chunk = RecursiveRetriever(\n",
        "    \"vector\",\n",
        "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
        "    node_dict=all_nodes_dict,\n",
        "    verbose=True,\n",
        ")\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
        ")\n",
        "\n",
        "results_chunk = await retriever_evaluator.aevaluate_dataset(\n",
        "    eval_dataset, show_progress=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "EqbEf9aP9_-5",
        "outputId": "532ba2b9-c293-41b4-c069-aad2dbe40106"
      },
      "outputs": [],
      "source": [
        "full_results_df = get_retrieval_results_df(\n",
        "    [\n",
        "        \"Base Retriever\",\n",
        "        \"Retriever (Chunk References)\"\n",
        "    ],\n",
        "    [results_base, results_chunk],\n",
        ")\n",
        "display(full_results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsj_n2hI08Bw"
      },
      "source": [
        "# Sentence Window Retrieval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGPlNnlL1NzE"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SentenceWindowNodeParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naJwk-SY06vv"
      },
      "outputs": [],
      "source": [
        "# create the sentence window node parser w/ default settings\n",
        "node_parser = SentenceWindowNodeParser.from_defaults(\n",
        "    window_size=3,\n",
        "    window_metadata_key=\"window\",\n",
        "    original_text_metadata_key=\"original_text\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE30uiuu1Lsz",
        "outputId": "fea6c051-4bf6-435b-ee34-c62f4402f0c8"
      },
      "outputs": [],
      "source": [
        "node_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xNTUIh_1Saw"
      },
      "outputs": [],
      "source": [
        "sentence_nodes = node_parser.get_nodes_from_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTc_xY_q1rUg"
      },
      "outputs": [],
      "source": [
        "sentence_index = VectorStoreIndex(sentence_nodes, service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDOgmEXE_QuZ"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
        "\n",
        "query_engine = sentence_index.as_query_engine(\n",
        "    similarity_top_k=2,\n",
        "    # the target key defaults to `window` to match the node_parser's default\n",
        "    node_postprocessors=[\n",
        "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ku1-C7d_x3J",
        "outputId": "d6db1e33-f80f-44ce-cff9-38a9c6cb1d74"
      },
      "outputs": [],
      "source": [
        "window_response = query_engine.query(\n",
        "    \"Can you tell me about the key concepts for safety finetuning\"\n",
        ")\n",
        "print(window_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95qZIGWw_5z0",
        "outputId": "dbb7834b-d84f-43f4-e4ce-590378aafcb8"
      },
      "outputs": [],
      "source": [
        "# check the original sentence that was retrieved for each node, as well as the actual window of sentences that was sent to the LLM.\n",
        "window = window_response.source_nodes[0].node.metadata[\"window\"]\n",
        "sentence = window_response.source_nodes[0].node.metadata[\"original_text\"]\n",
        "\n",
        "print(f\"Window: {window}\")\n",
        "print(\"------------------\")\n",
        "print(f\"Original Sentence: {sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3dJ8LcJbMn0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
