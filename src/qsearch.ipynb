{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    TYPE_CHECKING,\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    Type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qvdb import VectorDB\n",
    "\n",
    "qvdb = VectorDB(is_persistent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import warnings\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Suppress warnings about insecure HTTPS requests.\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)\n",
    "\n",
    "def extract_url_content(url: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extracts the content from the given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL to extract content from.\n",
    "\n",
    "        Returns:\n",
    "            str: The extracted content.\n",
    "        \"\"\"\n",
    "        response = requests.get(url, verify=False)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        text = ' '.join([p.text for p in soup.find_all('p')])  # Extract text from <p> tags\n",
    "\n",
    "        # We need to split it up into smaller pieces\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        text_splits = text_splitter.split_text(text)\n",
    "\n",
    "        return text_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "\n",
    "def search_and_store(qvdb: VectorDB, query: str, num_results: int = 5) -> None:\n",
    "        \"\"\"\n",
    "        Performs a Google Search for documents related to the given query,\n",
    "        extracts their content, and stores them in the vector store.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query to search for documents.\n",
    "            num_results (int): The number of URLs to retrieve. Defaults to 5.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        for index, url in enumerate(search(query, num_results)):\n",
    "            print(f\"<info> ({index}) Extracting content from: {url}\")\n",
    "            text_splits = extract_url_content(url=url)\n",
    "            for jindex, text in enumerate(text_splits):\n",
    "                qvdb.add(\n",
    "                    documents=[text],\n",
    "                    metadatas=[{\"source\": url}],\n",
    "                    ids=[f\"id{index}.{jindex}\"]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = 'mistral'\n",
    "model= 'llama3'\n",
    "system=\"\"\"\n",
    "You are a helpful AI assistant that helps answer questions based on documents and sources.\n",
    "You may combine your own knowledge with the information in the documents to answer the questions.\n",
    "If you make use of the provided documents then add the sources to the answer.\n",
    "Try to keep the column width of the response to 72 characters.\n",
    "\n",
    "Example of the documents:\n",
    "\n",
    "SOURCE: https://www.example.com\n",
    "DOCUMENT: This is an example document.\n",
    "\n",
    "\"\"\"\n",
    "template = \"\"\"\n",
    "Here is the question: {question}\n",
    "\n",
    "Here are the documents and the corresponding sources:\n",
    "{documents}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question = \"What makes Virus different from Bacteria?\"\n",
    "#question = \"How do I print just a few lines of a file using the sed command?\"\n",
    "#question = \"Elaborate on who came up with the Periodical System?\"\n",
    "#question = \"With the increasing problem of antibiotic resistance, what are the alternatives to antibiotics?\"\n",
    "#question = \"Who invented the Erlang programming language and what was the reason behind it?\"\n",
    "question = \"What are the main differences between the GPT and the BERT models?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<info> (0) Extracting content from: https://blog.invgate.com/gpt-3-vs-bert\n",
      "<info> (1) Extracting content from: https://medium.com/@prudhvithtavva/bert-vs-gpt-a-tale-of-two-transformers-that-revolutionized-nlp-11fff8e61984\n",
      "<info> (2) Extracting content from: https://softteco.com/blog/bert-vs-chatgpt\n",
      "<info> (3) Extracting content from: https://www.baeldung.com/cs/bert-vs-gpt-3-architecture\n",
      "<info> (4) Extracting content from: https://medium.com/@reyhaneh.esmailbeigi/bert-gpt-and-bart-a-short-comparison-5d6a57175fca\n",
      "<info> (5) Extracting content from: https://symbl.ai/developers/blog/gpt-3-versus-bert-a-high-level-comparison/\n",
      "<info> (6) Extracting content from: https://www.quora.com/What-are-the-differences-between-Googles-Bert-and-OpenAIs-GPT-2-artificial-intelligence-models\n"
     ]
    }
   ],
   "source": [
    "search_and_store(qvdb=qvdb, query=question, num_results=5)\n",
    "results = qvdb.query(question, num_results=5)\n",
    "#print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "for d, s in zip(results['documents'][0], results['metadatas'][0]):\n",
    "    docs.append(f\"SOURCE: {s['source']}\\nDOCUMENT: {d}\\n\")\n",
    "documents = ' '.join(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "prompt = template.format(question=question, documents=documents)\n",
    "output = ollama.generate(model=model, system=system, prompt=prompt, stream=False)\n",
    "response = output['response'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main differences between GPT and BERT models are:\n",
      "\n",
      "* Architecture: GPT-3 is an autoregressive model, while BERT is bidirectional.\n",
      "* Training datasets: GPT-3 was trained on 45TB of data, while BERT was trained on 3TB of data.\n",
      "* Size: GPT-3 has 1.5 billion parameters, while BERT has 340 million parameters.\n",
      "* Fine-tuning: GPT-3 can be fine-tuned on specific tasks with small datasets, while BERT requires training datasets tailored to particular tasks for effective performance.\n",
      "\n",
      "(Sources: https://blog.invgate.com/gpt-3-vs-bert and https://softteco.com/blog/bert-vs-chatgpt)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvdb.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
